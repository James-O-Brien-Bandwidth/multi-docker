# Docker Compose ---> This will handle container communication automatically ... no need to link containers manually (which was the old way of doing it)
version: "3"
services:
  client:
    #    restart: always
    image: "${DOCKER_ID}/multi-client"
    mem_limit: 128m
    hostname: client
    #todo - api is what we should refer to
  server:
    #    restart: always
    image: "${DOCKER_ID}/multi-server"
    mem_limit: 128m
    hostname: api
    environment:
      - REDIS_HOST=$REDIS_HOST
      - REDIS_PORT=$REDIS_PORT
      - PGUSER=$PGUSER
      - PGHOST=$PGHOST
      - PGDATABASE=$PGDATABASE
      - PGPASSWORD=$PGPASSWORD
      - PGPORT=$PGPORT
  worker:
    #    restart: always
    image: "${DOCKER_ID}/multi-worker"
    mem_limit: 128m
    hostname: worker
    environment:
      - REDIS_HOST=$REDIS_HOST
      - REDIS_PORT=$REDIS_PORT
  nginx:
    image: "${DOCKER_ID}/multi-nginx"
    mem_limit: 128m
    hostname: nginx
    ports:
      - "80:80"

# todo - No postgres or redis ... I suspect the reason for this is because on AWS ... we will have a dedicated RDS resource
# I create these in IAM
# AWS_ACCESS_KEY
# AWS_SECRET_KEY
